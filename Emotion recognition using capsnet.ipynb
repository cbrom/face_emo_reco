{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Layer, Reshape,Dense\n",
    "from keras.layers import Conv2D,Input\n",
    "from keras.models import Sequential\n",
    "from keras.models import  model_from_json\n",
    "# import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import dlib\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EMOTIONS = {\n",
    "#     0 : '0', #'anger', \n",
    "#     1 : '1', #'disgust', \n",
    "#     2 : '2', #'fear', \n",
    "#     3 : '3', #'happy', \n",
    "#     4 : '4', #'sad', \n",
    "#     5 : '5', #'surprise', \n",
    "#     6 : '6', #'neutral'\n",
    "# }\n",
    "\n",
    "EMOTIONS = {\n",
    "    0 : 'anger', \n",
    "    1 : 'disgust', \n",
    "    2 : 'fear', \n",
    "    3 : 'happy', \n",
    "    4 : 'sad', \n",
    "    5 : 'surprise', \n",
    "    6 : 'neutral'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Length(Layer):\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "    \n",
    "class CapsLayer(Layer):\n",
    "    def __init__(self, num_output = 32,\n",
    "        batch_size=32,length_dim = 8,num_caps = None,layer_type=\"pcap\",num_rout_iter=3,**kwargs):\n",
    "        \"\"\"\n",
    "        :param num_caps: number capsules in this layer\n",
    "        :param length_dim: dimension of capsules output length\n",
    "        :param layer_type: type of layer either primary capsule layer(pcap) or capsule layer(cap).\n",
    "        \"\"\"\n",
    "        super(CapsLayer, self).__init__(**kwargs)\n",
    "        self.num_output = num_output\n",
    "        self.length_dim = length_dim\n",
    "        self.layer_type = layer_type\n",
    "        self.num_rout_iter = num_rout_iter\n",
    "        self.num_caps = num_caps\n",
    "        \n",
    "    def call(self,input,kernel_size=[9,9],strides = 2,padding=\"valid\"):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        if (self.layer_type == \"pcap\"):\n",
    "            capsules = []\n",
    "            for i in range(self.num_output):\n",
    "                caps_i = Conv2D(self.length_dim,kernel_size=self.kernel_size,strides=self.strides,\n",
    "                    activation=\"relu\",padding=self.padding,name=\"conv_\"+str(i))(input)\n",
    "                caps_i_shape = caps_i.shape.as_list()\n",
    "                caps_i = K.reshape(caps_i,(-1,caps_i_shape[1] * caps_i_shape[2],self.length_dim))\n",
    "                capsules.append(caps_i)\n",
    "            capsules_shape = capsules[0].shape.as_list()\n",
    "            print(capsules_shape,\"primary caps\")\n",
    "            self.num_caps = capsules_shape[1] * self.num_output\n",
    "            capsules = keras.layers.concatenate(capsules, axis=1)\n",
    "            return capsules\n",
    "            \n",
    "                \n",
    "        elif (self.layer_type == \"cap\"):\n",
    "            # input.shape (-1,cpa)\n",
    "            self.net_input = input\n",
    "            caps = self.routing(self.net_input)\n",
    "            return caps\n",
    "        else:\n",
    "            raise Exception(\"Not implmented for \"+str(self.layer_type))\n",
    "    def routing(self,input):\n",
    "        \n",
    "        # input shape None,num_caps,input_length_dim\n",
    "        input = K.expand_dims(input,axis=2)\n",
    "        input = K.expand_dims(input,axis=3)\n",
    "        # None,input_num_caps,1,1,input_length_dim\n",
    "        input = K.tile(input,[1,1,self.num_caps,1,1])\n",
    "        # input shape (?, input_num_caps,self.num_caps,1,input_length_dim)\n",
    "        # weight shape (32, 32, 6, 6,10,8,16)\\\n",
    "        print(input.shape)\n",
    "        input_shape = input.shape.as_list()\n",
    "        weight_shape = [input_shape[1],self.num_caps,input_shape[4],self.length_dim]\n",
    "        self.W = self.add_weight(shape=weight_shape,\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 name='W')\n",
    "        self.b_IJ = self.add_weight(shape=[1,input_shape[1],self.num_caps,1,1],\n",
    "                                 initializer=\"zeros\",\n",
    "                                 name='bias',\n",
    "                                 trainable=False\n",
    "                                 )\n",
    "\n",
    "        inputs_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]),\n",
    "                             elems=input,\n",
    "                             initializer=K.zeros([input_shape[1], self.num_caps, 1, self.length_dim]))\n",
    "\n",
    "        print(\"uhat \", inputs_hat.shape)\n",
    "        # print \"uhat\", u_hat.shape\n",
    "        for iter in range(self.num_rout_iter):\n",
    "            # b_IJ shape b_J (1, 1152, 10, 1, 1)\n",
    "            c_IJ = tf.nn.softmax(self.b_IJ, dim=2)\n",
    "            s_J = K.sum(c_IJ * inputs_hat, 1, keepdims=True)\n",
    "            v_J = self.squash(s_J)\n",
    "            if iter!=self.num_rout_iter-1:\n",
    "                self.b_IJ += K.sum(inputs_hat * v_J, -1, keepdims=True)\n",
    "\n",
    "        v_J = K.reshape(v_J, [-1, self.num_caps, self.length_dim])\n",
    "        return v_J\n",
    "    def squash(self,vector):\n",
    "        vec_squared_norm = K.sum(K.square(vector),axis = -1, keepdims=True)\n",
    "        scalar_factor = vec_squared_norm / (1 + vec_squared_norm) / K.sqrt(vec_squared_norm)\n",
    "        vec_squashed = scalar_factor * vector  # element-wise\n",
    "        return(vec_squashed)\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return tuple([None, self.num_caps, self.length_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CapsNet(object):\n",
    "\n",
    "    def __init__(self,input_shape,lmd = 0.5,learing_rate = 1e-2):\n",
    "        \n",
    "        self.input = Input(shape=input_shape)\n",
    "        conv1 = Conv2D(32,activation=\"relu\",kernel_size=[9,9],strides=1,padding=\"valid\",name=\"conv1\")(self.input)\n",
    "        primaryCaps = CapsLayer(length_dim=8)(conv1,padding=\"valid\")\n",
    "        secondCaps = CapsLayer(num_caps = len(EMOTIONS),length_dim = 16,layer_type=\"cap\")(primaryCaps)\n",
    "        length = Length(name=\"pred\")(secondCaps)\n",
    "        self.model = Model(inputs=self.input,outputs=length)\n",
    "        self.learing_rate = learing_rate\n",
    "        self.lmd = lmd\n",
    "        self.input_shape = input_shape\n",
    "    def train(self):\n",
    "        \n",
    "        self.x_train, self.y_train = self.load_dataset(\"/home/cbs/workspace/private/mine/emods/ck_export/dataset/train/\",True)\n",
    "        self.x_test, self.y_test = self.load_dataset(\"/home/cbs/workspace/private/mine/emods/ck_export/dataset/test\",True)\n",
    "\n",
    "        self.x_train,self.y_train = shuffle(self.x_train,self.y_train)\n",
    "        self.x_test,self.y_test = shuffle(self.x_test,self.y_test)\n",
    "        \n",
    "        x_train = self.x_train.reshape((-1,self.input_shape[0],self.input_shape[1],1))\n",
    "        x_test = self.x_test.reshape((-1,self.input_shape[0],self.input_shape[1],1))\n",
    "        y_train = np.eye(len(EMOTIONS))[self.y_train]\n",
    "        y_test = np.eye(len(EMOTIONS))[self.y_test]\n",
    "     \n",
    "        self.model.compile(optimizer=keras.optimizers.Adam(self.learing_rate),\n",
    "                  loss=[self.margin_loss],\n",
    "                  metrics=['accuracy'])\n",
    "        self.model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=100,batch_size=32)\n",
    "\n",
    "        # datagen = ImageDataGenerator(\n",
    "        #     rotation_range=30,\n",
    "        #     width_shift_range = 0.2,\n",
    "        #     height_shift_range = 0.2,\n",
    "        #     shear_range = 0.2,\n",
    "        #     zoom_range = 0.2,\n",
    "        #     horizontal_flip = True,\n",
    "        # )\n",
    "        # self.model.fit_generator( datagen.flow(x_train,y_train, batch_size=32), \n",
    "        #                     steps_per_epoch = 1000,\n",
    "        #                     validation_data =(x_test,y_test),\n",
    "        #                     verbose = 1,\n",
    "        #                     epochs = 100\n",
    "        # )\n",
    "        self.model = Sequential()\n",
    "        self.model_json=self.model.to_json()\n",
    "#         with open(\"modelsmodel.json\",\"w\") as json_file:\n",
    "#             json_file.write(self.model_json)\n",
    "#         self.model.save_weights(\"models/all-model.h5\")\n",
    "    def string_to_emotion(self,string):\n",
    "        for emotion in EMOTIONS:\n",
    "            if EMOTIONS[emotion] == string:\n",
    "                return emotion\n",
    "        raise Exception(\"value \"+string,\" does not exist\")\n",
    "    def sanitize(self,img):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        img = cv2.resize(img, (self.input_shape[0],self.input_shape[1]))  # Resize\n",
    "        return img\n",
    "\n",
    "    def load_dataset(self,directory,verbose=True):\n",
    "        x, y = [], []\n",
    "\n",
    "        # Read images from the directory\n",
    "        for emotion_dir in os.listdir(directory):\n",
    "            if verbose:\n",
    "                print(\"loading\",emotion_dir,\"dataset\")\n",
    "            for filename in os.listdir(os.path.join(directory, emotion_dir)):\n",
    "                try:\n",
    "                    x += [self.sanitize(cv2.imread(os.path.join(directory, emotion_dir, filename)))]\n",
    "                except cv2.error as e:\n",
    "                    print(\"Error while reading \", os.path.join(directory, emotion_dir, filename))\n",
    "                    continue\n",
    "                y += [self.string_to_emotion(emotion_dir)]\n",
    "                # y +=[EMOTIONS(emotion_dir)]\n",
    "                \n",
    "\n",
    "        # Convert to numpy array\n",
    "        x = np.array(x, dtype='uint8')\n",
    "        y = np.array(y)\n",
    "\n",
    "        return x, y\n",
    "    def margin_loss(self,y_true, y_pred):\n",
    "       \n",
    "        L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "            self.lmd * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "        return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 27889, 8] primary caps\n",
      "(?, 892448, 7, 1, 8)\n",
      "uhat  (?, 892448, 7, 1, 16)\n",
      "loading happy dataset\n",
      "loading sadness dataset\n",
      "loading neutral dataset\n",
      "loading disgust dataset\n",
      "loading anger dataset\n",
      "loading contempt dataset\n",
      "loading surprise dataset\n",
      "loading fear dataset\n",
      "loading happy dataset\n",
      "loading sadness dataset\n",
      "loading neutral dataset\n",
      "loading disgust dataset\n",
      "loading anger dataset\n",
      "loading contempt dataset\n",
      "loading surprise dataset\n",
      "loading fear dataset\n",
      "Train on 874 samples, validate on 217 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "capsNet = CapsNet((350,350,1))\n",
    "capsNet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
